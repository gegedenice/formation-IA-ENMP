# Mod√®les audio : Speech-to-Text (STT) et Text-to-Speech (TTS)

Les mod√®les audio contemporains (STT et TTS) reposent sur les m√™mes briques conceptuelles que les mod√®les de langage modernes : transformers, embeddings multimodaux, encoders profonds, ou parfois mod√®le de diffusion.

Cependant la plupart du temps ce sont des mod√®les tr√®s l√©gers po

## Speech-to-Text (STT) ‚Äî Reconnaissance vocale

Les mod√®les STT modernes fonctionnent en deux grandes √©tapes :

* Encodage spectral
  * L‚Äôaudio est transform√© en spectrogramme , qui √©quivaut √† une image 2D trait√©e comme une s√©quence de patches.
* Encoder transformer
  * L‚Äôencoder extrait une repr√©sentation latente tr√®s dense du signal.
  * Exemples : OpenAI Whisper, Facebook Wav2Vec2, SpeechT5-Encoder, Distil-Whisper.
* D√©codage textuel
  * S'appuie soit sur un d√©codeur transformer (Whisper), soit une t√™te lin√©aire si le mod√®le pr√©dit directement les tokens (Wav2Vec2 ‚Üí CTC).

| Famille              | Exemple  | Particularit√©                                                             |
| -------------------- | -------- | ------------------------------------------------------------------------- |
| **CTC-based models** | Wav2Vec2 | Rapides, efficaces, moins bons sur la ponctuation & les langues multiples |
| **Encoder‚ÄìDecoder**  | Whisper  | Robuste, multilingue, g√®re les accents, les bruits, les horodatages       |

Exemple : [https://kyutai.org/next/stt](https://kyutai.org/next/stt)

## TTS

La synth√®se vocale moderne se fait en deux √©tapes :

* Acoustic Model (texte ‚Üí spectrogramme)
  * G√©n√©ralement un transformer (FastSpeech2, SpeechT5, VITS sans alignement explicite) apprend la prosodie, le rythme, l‚Äôintonation.
* Vocoder (spectrogramme ‚Üí onde sonore)
  * Le d√©codage bas√©s sur des mod√®les de diffusion (DiffWave) ou GAN (HiFi-GAN) g√©n√®rent un audio expressif.

#### üìå Trois types d‚Äôapproche

| Type                | Exemple     | Notes                                     |
| ------------------- | ----------- | ----------------------------------------- |
| **FastSpeech-like** | FastSpeech2 | Ultra rapide, qualit√© correcte            |
| **End-to-end**      | VITS        | Tr√®s naturels, entra√Ænement plus complexe |
| **Diffusion TTS**   | Grad-TTS    | Qualit√© sup√©rieure, plus lent             |

**Exemples**

[https://kyutai.org/next/tts](https://kyutai.org/next/tts)

[https://huggingface.co/spaces/neuphonic/neutts-air](https://huggingface.co/spaces/neuphonic/neutts-air)

Podcast √† partir de conversation : [https://huggingface.co/spaces/yasserrmd/VibeVoice](https://huggingface.co/spaces/yasserrmd/VibeVoice)

## Compl√©ment : les mod√®les ASR _temps r√©el_ (Real-Time / Streaming ASR)

Les mod√®les ASR tr√®s rapides (Automatic Speech Recognition) sont con√ßus pour fournir une transcription _pendant que la personne parle_, avec une latence de quelques dizaines de millisecondes.\
Ils diff√®rent des mod√®les STT ‚Äúoffline‚Äù comme Whisper par l‚Äôarchitecture et le mode de traitement.

Ils sont bas√©s sur du streaming incr√©mental o√π l‚Äôaudio n‚Äôest pas trait√© en un seul bloc mais en chunks (ex. 20‚Äì40 ms) dont le mod√®le met √† jour la transcription au fur et √† mesure.
